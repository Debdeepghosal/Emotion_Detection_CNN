{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1732825,"sourceType":"datasetVersion","datasetId":1028436}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np \nfrom PIL import Image\nimport tensorflow as tf\nimport keras\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-18T14:16:53.562367Z","iopub.execute_input":"2023-11-18T14:16:53.562784Z","iopub.status.idle":"2023-11-18T14:17:06.621994Z","shell.execute_reply.started":"2023-11-18T14:16:53.562754Z","shell.execute_reply":"2023-11-18T14:17:06.620922Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"#Function to find Pixel values of Images\ndef get_pixel_values(image_path):\n    img = Image.open(image_path)\n    return list(img.getdata())\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:17:06.624243Z","iopub.execute_input":"2023-11-18T14:17:06.625029Z","iopub.status.idle":"2023-11-18T14:17:06.635567Z","shell.execute_reply.started":"2023-11-18T14:17:06.624989Z","shell.execute_reply":"2023-11-18T14:17:06.629882Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Assigning Digits to Every Emotion","metadata":{}},{"cell_type":"code","source":"emotionList=[\"angry\",\"disgusted\",\"fearful\",\"happy\",\"neutral\",\"sad\",\"surprised\"]\nDigitAssigned={\"angry\":1,\"disgusted\":2,\"fearful\":3,\"happy\":4,\"neutral\":5,\"sad\":6,\"surprised\":7}","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:17:06.637282Z","iopub.execute_input":"2023-11-18T14:17:06.638265Z","iopub.status.idle":"2023-11-18T14:17:06.669682Z","shell.execute_reply.started":"2023-11-18T14:17:06.638203Z","shell.execute_reply":"2023-11-18T14:17:06.668464Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Find out Number of Images (Not Necessary)\nno_of_images=0\nfor emotion in emotionList:\n    no_of_images+=len(os.listdir(f\"/kaggle/input/emotion-detection-fer/train/{emotion}\"))\nno_of_images    ","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:17:06.672155Z","iopub.execute_input":"2023-11-18T14:17:06.676216Z","iopub.status.idle":"2023-11-18T14:17:09.595098Z","shell.execute_reply.started":"2023-11-18T14:17:06.676180Z","shell.execute_reply":"2023-11-18T14:17:09.594229Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"28709"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training and Testing Data","metadata":{}},{"cell_type":"code","source":"# Training Data\nall_image_pixel_values = []\nall_emotion_labels = []\n\nfor emotion in emotionList:\n    images = os.listdir(f\"/kaggle/input/emotion-detection-fer/train/{emotion}\")\n    image_paths = [f\"/kaggle/input/emotion-detection-fer/train/{emotion}/\" + img for img in images]\n    image_pixel_values = [get_pixel_values(img_path) for img_path in image_paths]\n    all_image_pixel_values.extend(image_pixel_values)\n    all_emotion_labels.extend([DigitAssigned[emotion]] * len(image_pixel_values))\n\nX_train = np.array(all_image_pixel_values)\ny_train = np.array(all_emotion_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:17:09.596125Z","iopub.execute_input":"2023-11-18T14:17:09.596390Z","iopub.status.idle":"2023-11-18T14:20:13.853773Z","shell.execute_reply.started":"2023-11-18T14:17:09.596354Z","shell.execute_reply":"2023-11-18T14:20:13.852634Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:13.855110Z","iopub.execute_input":"2023-11-18T14:20:13.855495Z","iopub.status.idle":"2023-11-18T14:20:13.864946Z","shell.execute_reply.started":"2023-11-18T14:20:13.855461Z","shell.execute_reply":"2023-11-18T14:20:13.863825Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(28709, 2304)"},"metadata":{}}]},{"cell_type":"code","source":"y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:13.866511Z","iopub.execute_input":"2023-11-18T14:20:13.867246Z","iopub.status.idle":"2023-11-18T14:20:13.876114Z","shell.execute_reply.started":"2023-11-18T14:20:13.867212Z","shell.execute_reply":"2023-11-18T14:20:13.875047Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(28709,)"},"metadata":{}}]},{"cell_type":"code","source":"#Randomizing the Training Distribution\nindices = np.random.permutation(len(X_train))\nX_train = X_train[indices]\ny_train = y_train[indices]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:13.877928Z","iopub.execute_input":"2023-11-18T14:20:13.878622Z","iopub.status.idle":"2023-11-18T14:20:14.048644Z","shell.execute_reply.started":"2023-11-18T14:20:13.878578Z","shell.execute_reply":"2023-11-18T14:20:14.047693Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:14.049726Z","iopub.execute_input":"2023-11-18T14:20:14.050010Z","iopub.status.idle":"2023-11-18T14:20:14.056904Z","shell.execute_reply.started":"2023-11-18T14:20:14.049987Z","shell.execute_reply":"2023-11-18T14:20:14.055920Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([[ 45,  61,  51, ..., 110,  51,  52],\n       [103, 105,  85, ..., 240, 238, 238],\n       [128, 126, 125, ...,  27,  29,  36],\n       ...,\n       [124, 128,  70, ..., 138, 137, 136],\n       [215, 215, 215, ..., 166, 167, 169],\n       [109, 110, 100, ...,  89,  88,  87]])"},"metadata":{}}]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:14.060779Z","iopub.execute_input":"2023-11-18T14:20:14.061103Z","iopub.status.idle":"2023-11-18T14:20:14.069315Z","shell.execute_reply.started":"2023-11-18T14:20:14.061060Z","shell.execute_reply":"2023-11-18T14:20:14.068352Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([3, 4, 3, ..., 1, 5, 4])"},"metadata":{}}]},{"cell_type":"code","source":"# Test Data\nall_image_pixel_values = []\nall_emotion_labels = []\n\nfor emotion in emotionList:\n    images = os.listdir(f\"/kaggle/input/emotion-detection-fer/test/{emotion}\")\n    image_paths = [f\"/kaggle/input/emotion-detection-fer/test/{emotion}/\" + img for img in images]\n    image_pixel_values = [get_pixel_values(img_path) for img_path in image_paths]\n    all_image_pixel_values.extend(image_pixel_values)\n    all_emotion_labels.extend([DigitAssigned[emotion]] * len(image_pixel_values))\n\n\nX_test = np.array(all_image_pixel_values)\ny_test = np.array(all_emotion_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:14.070388Z","iopub.execute_input":"2023-11-18T14:20:14.070712Z","iopub.status.idle":"2023-11-18T14:20:52.867855Z","shell.execute_reply.started":"2023-11-18T14:20:14.070680Z","shell.execute_reply":"2023-11-18T14:20:52.866798Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:52.869026Z","iopub.execute_input":"2023-11-18T14:20:52.869325Z","iopub.status.idle":"2023-11-18T14:20:52.875544Z","shell.execute_reply.started":"2023-11-18T14:20:52.869299Z","shell.execute_reply":"2023-11-18T14:20:52.874573Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(7178, 2304)"},"metadata":{}}]},{"cell_type":"code","source":"y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:52.876755Z","iopub.execute_input":"2023-11-18T14:20:52.877119Z","iopub.status.idle":"2023-11-18T14:20:52.887858Z","shell.execute_reply.started":"2023-11-18T14:20:52.877088Z","shell.execute_reply":"2023-11-18T14:20:52.886981Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(7178,)"},"metadata":{}}]},{"cell_type":"code","source":"#Dividing by 255 to normalize\nX_train=X_train/255.0\nX_test=X_test/255.0","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:52.888982Z","iopub.execute_input":"2023-11-18T14:20:52.889283Z","iopub.status.idle":"2023-11-18T14:20:53.159040Z","shell.execute_reply.started":"2023-11-18T14:20:52.889259Z","shell.execute_reply":"2023-11-18T14:20:53.157890Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#Reshaping the array\nX_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\nX_test = X_test.reshape(X_test.shape[0], 48, 48, 1)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:53.160539Z","iopub.execute_input":"2023-11-18T14:20:53.161679Z","iopub.status.idle":"2023-11-18T14:20:53.166848Z","shell.execute_reply.started":"2023-11-18T14:20:53.161647Z","shell.execute_reply":"2023-11-18T14:20:53.165835Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:53.168173Z","iopub.execute_input":"2023-11-18T14:20:53.168555Z","iopub.status.idle":"2023-11-18T14:20:53.180339Z","shell.execute_reply.started":"2023-11-18T14:20:53.168521Z","shell.execute_reply":"2023-11-18T14:20:53.179443Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(28709, 48, 48, 1)"},"metadata":{}}]},{"cell_type":"code","source":"#One hot encoding\ny_train= keras.utils.to_categorical(y_train)[:,1:]\ny_test = keras.utils.to_categorical(y_test)[:,1:]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:53.181401Z","iopub.execute_input":"2023-11-18T14:20:53.181757Z","iopub.status.idle":"2023-11-18T14:20:53.192254Z","shell.execute_reply.started":"2023-11-18T14:20:53.181723Z","shell.execute_reply":"2023-11-18T14:20:53.191211Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#Creating Validation Set\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:53.193496Z","iopub.execute_input":"2023-11-18T14:20:53.193847Z","iopub.status.idle":"2023-11-18T14:20:53.239067Z","shell.execute_reply.started":"2023-11-18T14:20:53.193816Z","shell.execute_reply":"2023-11-18T14:20:53.238075Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:53.240257Z","iopub.execute_input":"2023-11-18T14:20:53.240559Z","iopub.status.idle":"2023-11-18T14:20:53.247273Z","shell.execute_reply.started":"2023-11-18T14:20:53.240533Z","shell.execute_reply":"2023-11-18T14:20:53.246385Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [1., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"#Necessary imports\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import concatenate\nfrom keras.optimizers import Adam, SGD\nfrom keras.regularizers import l1, l2","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:53.248333Z","iopub.execute_input":"2023-11-18T14:20:53.248656Z","iopub.status.idle":"2023-11-18T14:20:53.258489Z","shell.execute_reply.started":"2023-11-18T14:20:53.248632Z","shell.execute_reply":"2023-11-18T14:20:53.257614Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Model Creation","metadata":{}},{"cell_type":"code","source":"\ndef Emotion_Model(input_shape=(48,48,1)):\n    inputImg = Input(shape=input_shape, name='input')\n    num_classes = 7\n\n    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(inputImg)\n    conv1_1 = BatchNormalization()(conv1_1)\n    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n    conv1_2 = BatchNormalization()(conv1_2)\n    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)\n    \n    \n    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n    conv2_1 = BatchNormalization()(conv2_1)\n    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n    conv2_2 = BatchNormalization()(conv2_2)\n    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n    conv2_3 = BatchNormalization()(conv2_3)\n    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)\n    \n    \n    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n    conv3_1 = BatchNormalization()(conv3_1)\n    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n    conv3_2 = BatchNormalization()(conv3_2)\n    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n    conv3_3 = BatchNormalization()(conv3_3)\n    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n    conv3_4 = BatchNormalization()(conv3_4)\n    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)\n    \n    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n    conv4_1 = BatchNormalization()(conv4_1)\n    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n    conv4_2 = BatchNormalization()(conv4_2)\n    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n    conv4_3 = BatchNormalization()(conv4_3)\n    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n    conv4_4 = BatchNormalization()(conv4_4)\n    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n    \n    \n    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n    conv5_1 = BatchNormalization()(conv5_1)\n    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n    conv5_2 = BatchNormalization()(conv5_2)\n    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n    conv5_3 = BatchNormalization()(conv5_3)\n    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n    conv5_3 = BatchNormalization()(conv5_4)\n    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)\n    flatten = Flatten(name = 'flatten')(drop5_1)\n    ouput = Dense(7, activation='softmax', name = 'output')(flatten)\n    model = Model(inputs =inputImg, outputs = ouput)\n    \n    print(model.summary())\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:53.259631Z","iopub.execute_input":"2023-11-18T14:20:53.259947Z","iopub.status.idle":"2023-11-18T14:20:53.281230Z","shell.execute_reply.started":"2023-11-18T14:20:53.259916Z","shell.execute_reply":"2023-11-18T14:20:53.280293Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"checkpointer = [EarlyStopping(monitor = 'val_accuracy', verbose = 1, \n                              restore_best_weights=True,mode=\"max\",patience = 5),\n                ModelCheckpoint('best_model.h5',monitor=\"val_accuracy\",verbose=1,\n                                save_best_only=True,mode=\"max\")]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:53.295694Z","iopub.execute_input":"2023-11-18T14:20:53.296333Z","iopub.status.idle":"2023-11-18T14:20:53.306186Z","shell.execute_reply.started":"2023-11-18T14:20:53.296300Z","shell.execute_reply":"2023-11-18T14:20:53.305426Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#Model Compilation\nmodel = Emotion_Model()\noptimizer = Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:20:53.330851Z","iopub.execute_input":"2023-11-18T14:20:53.331717Z","iopub.status.idle":"2023-11-18T14:20:57.934317Z","shell.execute_reply.started":"2023-11-18T14:20:53.331692Z","shell.execute_reply":"2023-11-18T14:20:57.933371Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input (InputLayer)          [(None, 48, 48, 1)]       0         \n                                                                 \n conv1_1 (Conv2D)            (None, 48, 48, 64)        640       \n                                                                 \n batch_normalization (Batch  (None, 48, 48, 64)        256       \n Normalization)                                                  \n                                                                 \n conv1_2 (Conv2D)            (None, 48, 48, 64)        36928     \n                                                                 \n batch_normalization_1 (Bat  (None, 48, 48, 64)        256       \n chNormalization)                                                \n                                                                 \n pool1_1 (MaxPooling2D)      (None, 24, 24, 64)        0         \n                                                                 \n drop1_1 (Dropout)           (None, 24, 24, 64)        0         \n                                                                 \n conv2_1 (Conv2D)            (None, 24, 24, 128)       73856     \n                                                                 \n batch_normalization_2 (Bat  (None, 24, 24, 128)       512       \n chNormalization)                                                \n                                                                 \n conv2_2 (Conv2D)            (None, 24, 24, 128)       147584    \n                                                                 \n batch_normalization_3 (Bat  (None, 24, 24, 128)       512       \n chNormalization)                                                \n                                                                 \n conv2_3 (Conv2D)            (None, 24, 24, 128)       147584    \n                                                                 \n batch_normalization_4 (Bat  (None, 24, 24, 128)       512       \n chNormalization)                                                \n                                                                 \n pool2_1 (MaxPooling2D)      (None, 12, 12, 128)       0         \n                                                                 \n drop2_1 (Dropout)           (None, 12, 12, 128)       0         \n                                                                 \n conv3_1 (Conv2D)            (None, 12, 12, 256)       295168    \n                                                                 \n batch_normalization_5 (Bat  (None, 12, 12, 256)       1024      \n chNormalization)                                                \n                                                                 \n conv3_2 (Conv2D)            (None, 12, 12, 256)       590080    \n                                                                 \n batch_normalization_6 (Bat  (None, 12, 12, 256)       1024      \n chNormalization)                                                \n                                                                 \n conv3_3 (Conv2D)            (None, 12, 12, 256)       590080    \n                                                                 \n batch_normalization_7 (Bat  (None, 12, 12, 256)       1024      \n chNormalization)                                                \n                                                                 \n conv3_4 (Conv2D)            (None, 12, 12, 256)       590080    \n                                                                 \n batch_normalization_8 (Bat  (None, 12, 12, 256)       1024      \n chNormalization)                                                \n                                                                 \n pool3_1 (MaxPooling2D)      (None, 6, 6, 256)         0         \n                                                                 \n drop3_1 (Dropout)           (None, 6, 6, 256)         0         \n                                                                 \n conv4_1 (Conv2D)            (None, 6, 6, 256)         590080    \n                                                                 \n batch_normalization_9 (Bat  (None, 6, 6, 256)         1024      \n chNormalization)                                                \n                                                                 \n conv4_2 (Conv2D)            (None, 6, 6, 256)         590080    \n                                                                 \n batch_normalization_10 (Ba  (None, 6, 6, 256)         1024      \n tchNormalization)                                               \n                                                                 \n conv4_3 (Conv2D)            (None, 6, 6, 256)         590080    \n                                                                 \n batch_normalization_11 (Ba  (None, 6, 6, 256)         1024      \n tchNormalization)                                               \n                                                                 \n conv4_4 (Conv2D)            (None, 6, 6, 256)         590080    \n                                                                 \n batch_normalization_12 (Ba  (None, 6, 6, 256)         1024      \n tchNormalization)                                               \n                                                                 \n pool4_1 (MaxPooling2D)      (None, 3, 3, 256)         0         \n                                                                 \n drop4_1 (Dropout)           (None, 3, 3, 256)         0         \n                                                                 \n conv5_1 (Conv2D)            (None, 3, 3, 512)         1180160   \n                                                                 \n batch_normalization_13 (Ba  (None, 3, 3, 512)         2048      \n tchNormalization)                                               \n                                                                 \n conv5_2 (Conv2D)            (None, 3, 3, 512)         2359808   \n                                                                 \n batch_normalization_14 (Ba  (None, 3, 3, 512)         2048      \n tchNormalization)                                               \n                                                                 \n conv5_3 (Conv2D)            (None, 3, 3, 512)         2359808   \n                                                                 \n batch_normalization_15 (Ba  (None, 3, 3, 512)         2048      \n tchNormalization)                                               \n                                                                 \n conv5_4 (Conv2D)            (None, 3, 3, 512)         2359808   \n                                                                 \n pool5_1 (MaxPooling2D)      (None, 1, 1, 512)         0         \n                                                                 \n drop5_1 (Dropout)           (None, 1, 1, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 512)               0         \n                                                                 \n output (Dense)              (None, 7)                 3591      \n                                                                 \n=================================================================\nTotal params: 13111879 (50.02 MB)\nTrainable params: 13103687 (49.99 MB)\nNon-trainable params: 8192 (32.00 KB)\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"#Training the Model\nModelHistory = model.fit(X_train, y_train,\n                    epochs=100,\n                    batch_size=64,   \n                    verbose=1,\n                    callbacks=[checkpointer],\n                    validation_data=(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:21:04.547645Z","iopub.execute_input":"2023-11-18T14:21:04.548420Z","iopub.status.idle":"2023-11-18T14:38:52.314875Z","shell.execute_reply.started":"2023-11-18T14:21:04.548371Z","shell.execute_reply":"2023-11-18T14:38:52.313879Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2023-11-18 14:21:09.531056: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/drop1_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"449/449 [==============================] - ETA: 0s - loss: 2.1545 - accuracy: 0.2381\nEpoch 1: val_accuracy improved from -inf to 0.25327, saving model to best_model.h5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"449/449 [==============================] - 60s 85ms/step - loss: 2.1545 - accuracy: 0.2381 - val_loss: 1.8635 - val_accuracy: 0.2533\nEpoch 2/100\n449/449 [==============================] - ETA: 0s - loss: 1.6315 - accuracy: 0.3539\nEpoch 2: val_accuracy improved from 0.25327 to 0.40791, saving model to best_model.h5\n449/449 [==============================] - 38s 84ms/step - loss: 1.6315 - accuracy: 0.3539 - val_loss: 1.5247 - val_accuracy: 0.4079\nEpoch 3/100\n449/449 [==============================] - ETA: 0s - loss: 1.4156 - accuracy: 0.4545\nEpoch 3: val_accuracy improved from 0.40791 to 0.46893, saving model to best_model.h5\n449/449 [==============================] - 38s 85ms/step - loss: 1.4156 - accuracy: 0.4545 - val_loss: 1.3711 - val_accuracy: 0.4689\nEpoch 4/100\n449/449 [==============================] - ETA: 0s - loss: 1.2934 - accuracy: 0.5009\nEpoch 4: val_accuracy improved from 0.46893 to 0.51491, saving model to best_model.h5\n449/449 [==============================] - 39s 88ms/step - loss: 1.2934 - accuracy: 0.5009 - val_loss: 1.2871 - val_accuracy: 0.5149\nEpoch 5/100\n449/449 [==============================] - ETA: 0s - loss: 1.2213 - accuracy: 0.5363\nEpoch 5: val_accuracy improved from 0.51491 to 0.53887, saving model to best_model.h5\n449/449 [==============================] - 39s 87ms/step - loss: 1.2213 - accuracy: 0.5363 - val_loss: 1.2157 - val_accuracy: 0.5389\nEpoch 6/100\n449/449 [==============================] - ETA: 0s - loss: 1.1644 - accuracy: 0.5580\nEpoch 6: val_accuracy improved from 0.53887 to 0.55029, saving model to best_model.h5\n449/449 [==============================] - 39s 87ms/step - loss: 1.1644 - accuracy: 0.5580 - val_loss: 1.2019 - val_accuracy: 0.5503\nEpoch 7/100\n449/449 [==============================] - ETA: 0s - loss: 1.1082 - accuracy: 0.5822\nEpoch 7: val_accuracy improved from 0.55029 to 0.56032, saving model to best_model.h5\n449/449 [==============================] - 39s 87ms/step - loss: 1.1082 - accuracy: 0.5822 - val_loss: 1.1716 - val_accuracy: 0.5603\nEpoch 8/100\n449/449 [==============================] - ETA: 0s - loss: 1.0593 - accuracy: 0.6026\nEpoch 8: val_accuracy improved from 0.56032 to 0.58122, saving model to best_model.h5\n449/449 [==============================] - 39s 87ms/step - loss: 1.0593 - accuracy: 0.6026 - val_loss: 1.1475 - val_accuracy: 0.5812\nEpoch 9/100\n449/449 [==============================] - ETA: 0s - loss: 1.0331 - accuracy: 0.6151\nEpoch 9: val_accuracy improved from 0.58122 to 0.58819, saving model to best_model.h5\n449/449 [==============================] - 39s 87ms/step - loss: 1.0331 - accuracy: 0.6151 - val_loss: 1.1564 - val_accuracy: 0.5882\nEpoch 10/100\n449/449 [==============================] - ETA: 0s - loss: 0.9832 - accuracy: 0.6357\nEpoch 10: val_accuracy did not improve from 0.58819\n449/449 [==============================] - 39s 86ms/step - loss: 0.9832 - accuracy: 0.6357 - val_loss: 1.4412 - val_accuracy: 0.5386\nEpoch 11/100\n449/449 [==============================] - ETA: 0s - loss: 0.9529 - accuracy: 0.6450\nEpoch 11: val_accuracy did not improve from 0.58819\n449/449 [==============================] - 39s 86ms/step - loss: 0.9529 - accuracy: 0.6450 - val_loss: 1.1820 - val_accuracy: 0.5745\nEpoch 12/100\n449/449 [==============================] - ETA: 0s - loss: 0.9172 - accuracy: 0.6633\nEpoch 12: val_accuracy improved from 0.58819 to 0.58958, saving model to best_model.h5\n449/449 [==============================] - 39s 87ms/step - loss: 0.9172 - accuracy: 0.6633 - val_loss: 1.1499 - val_accuracy: 0.5896\nEpoch 13/100\n449/449 [==============================] - ETA: 0s - loss: 0.8962 - accuracy: 0.6700\nEpoch 13: val_accuracy improved from 0.58958 to 0.60936, saving model to best_model.h5\n449/449 [==============================] - 39s 87ms/step - loss: 0.8962 - accuracy: 0.6700 - val_loss: 1.0830 - val_accuracy: 0.6094\nEpoch 14/100\n449/449 [==============================] - ETA: 0s - loss: 0.8912 - accuracy: 0.6730\nEpoch 14: val_accuracy improved from 0.60936 to 0.60964, saving model to best_model.h5\n449/449 [==============================] - 39s 87ms/step - loss: 0.8912 - accuracy: 0.6730 - val_loss: 1.1456 - val_accuracy: 0.6096\nEpoch 15/100\n449/449 [==============================] - ETA: 0s - loss: 0.8214 - accuracy: 0.6981\nEpoch 15: val_accuracy improved from 0.60964 to 0.62914, saving model to best_model.h5\n449/449 [==============================] - 39s 87ms/step - loss: 0.8214 - accuracy: 0.6981 - val_loss: 1.0572 - val_accuracy: 0.6291\nEpoch 16/100\n449/449 [==============================] - ETA: 0s - loss: 0.7645 - accuracy: 0.7200\nEpoch 16: val_accuracy did not improve from 0.62914\n449/449 [==============================] - 38s 86ms/step - loss: 0.7645 - accuracy: 0.7200 - val_loss: 1.0662 - val_accuracy: 0.6205\nEpoch 17/100\n449/449 [==============================] - ETA: 0s - loss: 0.7180 - accuracy: 0.7384\nEpoch 17: val_accuracy improved from 0.62914 to 0.63472, saving model to best_model.h5\n449/449 [==============================] - 39s 87ms/step - loss: 0.7180 - accuracy: 0.7384 - val_loss: 1.0477 - val_accuracy: 0.6347\nEpoch 18/100\n449/449 [==============================] - ETA: 0s - loss: 0.6767 - accuracy: 0.7565\nEpoch 18: val_accuracy did not improve from 0.63472\n449/449 [==============================] - 38s 86ms/step - loss: 0.6767 - accuracy: 0.7565 - val_loss: 1.0923 - val_accuracy: 0.6085\nEpoch 19/100\n449/449 [==============================] - ETA: 0s - loss: 0.6363 - accuracy: 0.7720\nEpoch 19: val_accuracy did not improve from 0.63472\n449/449 [==============================] - 38s 86ms/step - loss: 0.6363 - accuracy: 0.7720 - val_loss: 1.1067 - val_accuracy: 0.6328\nEpoch 20/100\n449/449 [==============================] - ETA: 0s - loss: 0.5752 - accuracy: 0.7957\nEpoch 20: val_accuracy improved from 0.63472 to 0.64809, saving model to best_model.h5\n449/449 [==============================] - 39s 87ms/step - loss: 0.5752 - accuracy: 0.7957 - val_loss: 1.0913 - val_accuracy: 0.6481\nEpoch 21/100\n449/449 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.8133\nEpoch 21: val_accuracy did not improve from 0.64809\n449/449 [==============================] - 38s 86ms/step - loss: 0.5287 - accuracy: 0.8133 - val_loss: 1.1816 - val_accuracy: 0.6453\nEpoch 22/100\n449/449 [==============================] - ETA: 0s - loss: 0.4736 - accuracy: 0.8320\nEpoch 22: val_accuracy improved from 0.64809 to 0.66369, saving model to best_model.h5\n449/449 [==============================] - 39s 87ms/step - loss: 0.4736 - accuracy: 0.8320 - val_loss: 1.0932 - val_accuracy: 0.6637\nEpoch 23/100\n449/449 [==============================] - ETA: 0s - loss: 0.4185 - accuracy: 0.8523\nEpoch 23: val_accuracy did not improve from 0.66369\n449/449 [==============================] - 38s 85ms/step - loss: 0.4185 - accuracy: 0.8523 - val_loss: 1.2054 - val_accuracy: 0.6442\nEpoch 24/100\n449/449 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.8688\nEpoch 24: val_accuracy did not improve from 0.66369\n449/449 [==============================] - 38s 85ms/step - loss: 0.3814 - accuracy: 0.8688 - val_loss: 1.2748 - val_accuracy: 0.6464\nEpoch 25/100\n449/449 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.8785\nEpoch 25: val_accuracy did not improve from 0.66369\n449/449 [==============================] - 38s 85ms/step - loss: 0.3513 - accuracy: 0.8785 - val_loss: 1.3404 - val_accuracy: 0.6434\nEpoch 26/100\n449/449 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.8439\nEpoch 26: val_accuracy did not improve from 0.66369\n449/449 [==============================] - 38s 85ms/step - loss: 0.4446 - accuracy: 0.8439 - val_loss: 1.2957 - val_accuracy: 0.6595\nEpoch 27/100\n449/449 [==============================] - ETA: 0s - loss: 0.3120 - accuracy: 0.8926Restoring model weights from the end of the best epoch: 22.\n\nEpoch 27: val_accuracy did not improve from 0.66369\n449/449 [==============================] - 38s 86ms/step - loss: 0.3120 - accuracy: 0.8926 - val_loss: 1.4256 - val_accuracy: 0.6525\nEpoch 27: early stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"#Calculating Loss\nloss = model.evaluate(X_test,y_test)\nprint(\"Test Acc: \" + str(loss[1]))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:38:52.316534Z","iopub.execute_input":"2023-11-18T14:38:52.316827Z","iopub.status.idle":"2023-11-18T14:39:33.983771Z","shell.execute_reply.started":"2023-11-18T14:38:52.316802Z","shell.execute_reply":"2023-11-18T14:39:33.982773Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"113/113 [==============================] - 2s 13ms/step - loss: 1.1005 - accuracy: 0.6562\nTest Acc: 0.6561716198921204\n","output_type":"stream"}]},{"cell_type":"code","source":"#Saving the Model\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","metadata":{"execution":{"iopub.status.busy":"2023-11-18T14:39:33.985104Z","iopub.execute_input":"2023-11-18T14:39:33.985835Z","iopub.status.idle":"2023-11-18T14:39:34.149102Z","shell.execute_reply.started":"2023-11-18T14:39:33.985795Z","shell.execute_reply":"2023-11-18T14:39:34.148110Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Saved model to disk\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}